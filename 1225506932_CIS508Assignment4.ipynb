{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e978e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dipti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#NLTK-------------------------------\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Import libraries for feature \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import libraries for feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a4c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 2)\n",
      "(2070, 17)\n"
     ]
    }
   ],
   "source": [
    "#Read files\n",
    "textfile = r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\Comments.csv'\n",
    "textData = pd.read_csv(textfile) #creates a dataframe\n",
    "\n",
    "CustInfofile = r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\Customers.csv'\n",
    "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
    "\n",
    "print(textData.shape)\n",
    "print(CustInfoData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0206ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 16)\n",
      "   ID Sex Status  Children  Est_Income Car_Owner   Usage        Age  RatePlan  \\\n",
      "0   1   F      S         1    38000.00         N  229.64  24.393333         3   \n",
      "1   6   M      M         2    29616.00         N   75.29  49.426667         2   \n",
      "2   8   M      M         0    19732.80         N   47.25  50.673333         3   \n",
      "3  11   M      S         2       96.33         N   59.01  56.473333         1   \n",
      "4  14   F      M         2    52004.80         N   28.14  25.140000         1   \n",
      "\n",
      "   LongDistance  International   Local  Dropped Paymethod LocalBilltype  \\\n",
      "0         23.56            0.0  206.08        0        CC        Budget   \n",
      "1         29.78            0.0   45.50        0        CH     FreeLocal   \n",
      "2         24.81            0.0   22.44        0        CC     FreeLocal   \n",
      "3         26.13            0.0   32.88        1        CC        Budget   \n",
      "4          5.03            0.0   23.11        0        CH        Budget   \n",
      "\n",
      "  LongDistanceBilltype  \n",
      "0       Intnl_discount  \n",
      "1             Standard  \n",
      "2             Standard  \n",
      "3             Standard  \n",
      "4       Intnl_discount  \n",
      "(2070, 2)\n",
      "     ID                                           Comments\n",
      "0  1309  Does not like the way the phone works. It is t...\n",
      "1  3556  Wanted to know the nearest store location. Wan...\n",
      "2  2230  Wants to know how to do text messaging. Referr...\n",
      "3  2312  Asked how to disable call waiting. referred hi...\n",
      "4  3327  Needs help learning how to use the phone. I su...\n",
      "0       Cancelled\n",
      "1         Current\n",
      "2         Current\n",
      "3         Current\n",
      "4       Cancelled\n",
      "          ...    \n",
      "2065    Cancelled\n",
      "2066    Cancelled\n",
      "2067    Cancelled\n",
      "2068    Cancelled\n",
      "2069    Cancelled\n",
      "Name: TARGET, Length: 2070, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Extract target column from Customer Info file\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
    "                     \n",
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "print(textData.shape)\n",
    "print(textData.head())\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca51ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize - Split the sentences to lists of words\n",
    "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
    "\n",
    "export_csv = textData.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\TextDataTokenized1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bde812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use English stemmer.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#Now do stemming - create a new dataframe to store stemmed version\n",
    "newTextData=pd.DataFrame()\n",
    "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
    "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "\n",
    "export_csv = newTextData.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\newTextDataTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6a87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Join stemmed strings\n",
    "newTextData['CommentsTokenizedStemmed'] = newTextData['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "export_csv = newTextData.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\newTextData-Joined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e0e9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 354)\n",
      "int64\n",
      "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n",
      "      0    1    2    3    4    5    6    7    8    9    ...  344  345  346  \\\n",
      "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1       0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
      "2       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2065    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2066    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2067    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2068    0    0    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
      "2069    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "      347  348  349  350  351  352  353  \n",
      "0       1    0    0    0    0    0    0  \n",
      "1       0    0    0    0    0    0    0  \n",
      "2       0    0    0    0    0    0    0  \n",
      "3       0    0    0    0    0    0    0  \n",
      "4       0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "2065    0    0    0    0    0    0    0  \n",
      "2066    0    0    0    0    0    0    0  \n",
      "2067    0    0    0    0    0    0    0  \n",
      "2068    0    0    0    0    0    0    0  \n",
      "2069    0    0    0    0    0    0    0  \n",
      "\n",
      "[2070 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#Do Bag-Of-Words model - Term - Document Matrix\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "#count_vect = CountVectorizer(stop_words=None)\n",
    "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
    "TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmed)\n",
    "print(TD_counts.shape)\n",
    "print(TD_counts.dtype)\n",
    "print(count_vect.get_feature_names())\n",
    "#print(TD_counts)\n",
    "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
    "print(DF_TD_Counts)\n",
    "export_csv = DF_TD_Counts.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\TD_counts-TokenizedStemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cca7795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 354)\n",
      "      0    1    2    3        4    5    6    7    8         9    ...  344  \\\n",
      "0     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "1     0.0  0.0  0.0  0.0  0.27568  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "3     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "4     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "...   ...  ...  ...  ...      ...  ...  ...  ...  ...       ...  ...  ...   \n",
      "2065  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2066  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2067  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2068  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.772949  ...  0.0   \n",
      "2069  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "\n",
      "      345  346       347  348  349  350  351  352  353  \n",
      "0     0.0  0.0  0.209678  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
      "2065  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2066  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2067  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2068  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2069  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2070 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#Compute TF-IDF Matrix\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
    "print(DF_TF_IDF)\n",
    "export_csv= DF_TF_IDF.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\TFIDF_counts-TokenizedStemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68dc2bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 25)\n",
      "[ 14  49  50  51  62  70  81 115 118 121 186 190 212 217 222 235 239 248\n",
      " 249 259 273 307 313 319 342]\n",
      "       0         1         2    3    4    5    6         7    8         9   \\\n",
      "0     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "1     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "3     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "4     0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "...   ...       ...       ...  ...  ...  ...  ...       ...  ...       ...   \n",
      "2065  0.0  0.000000  0.446161  0.0  0.0  0.0  0.0  0.460113  0.0  0.457852   \n",
      "2066  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2067  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2068  0.0  0.545354  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "2069  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "      ...   15   16   17   18   19   20   21   22   23   24  \n",
      "0     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2065  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2066  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2067  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2068  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2069  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2070 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#Feature selection\n",
    "#Suppose, we select 50 features with top 50 Fisher scores\n",
    "selector = SelectKBest(k=25)\n",
    "#selector = SelectKBest(score_func=chi2, k=25)\n",
    "\n",
    "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
    "new_DF_TF_IDF = selector.fit_transform(DF_TF_IDF,y_train)\n",
    "print(new_DF_TF_IDF.shape)\n",
    "\n",
    "feature_names_out = selector.get_support(indices=True)\n",
    "print(feature_names_out)\n",
    "\n",
    "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
    "print(DF_TF_IDF_SelectedFeatures)\n",
    "\n",
    "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\TFIDF_counts-Selected Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6440f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.630435\n",
      "Confusion Matrix:\n",
      "[[  61  743]\n",
      " [  22 1244]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.73      0.08      0.14       804\n",
      "     Current       0.63      0.98      0.76      1266\n",
      "\n",
      "    accuracy                           0.63      2070\n",
      "   macro avg       0.68      0.53      0.45      2070\n",
      "weighted avg       0.67      0.63      0.52      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on text data\n",
    "clf=RandomForestClassifier()\n",
    "RF_text = clf.fit(DF_TF_IDF_SelectedFeatures,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(DF_TF_IDF_SelectedFeatures, y_train)))\n",
    "rf_predictions = clf.predict(DF_TF_IDF_SelectedFeatures)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8bff275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Accuracy Scores ===\n",
      "[0.52864886 0.48896632 0.51645374 0.53290747 0.496875   0.5546875\n",
      " 0.5265625  0.5234375  0.496875   0.5390625  0.54206349 0.52619048\n",
      " 0.49662698 0.525      0.52619048 0.49662698 0.5125     0.53075397\n",
      " 0.48075397 0.50119048]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - ON Text:  0.5171186604723189\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run cross-validation - Text Data\n",
    "clf_cv_score = cross_val_score(clf, DF_TF_IDF_SelectedFeatures, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
    "print(\"=== All Accuracy Scores ===\")\n",
    "print(clf_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean Accuracy Score ===\")\n",
    "print(\"Mean Accuracy Score - ON Text: \",clf_cv_score.mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e049f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 370)\n"
     ]
    }
   ],
   "source": [
    "#merge files\n",
    "DF_TF_IDF['ID'] = textData['ID']\n",
    "combined = pd.merge(X_train, DF_TF_IDF, on ='ID')\n",
    "print(combined.shape)\n",
    "combined.head()\n",
    "export_csv= combined.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\Combined2-Cust+TFIDF+SelectedFeatures.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62296e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
      "(2070, 378)\n"
     ]
    }
   ],
   "source": [
    "#Do one Hot encoding for categorical features\n",
    "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
    "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
    "print(X_cat)\n",
    "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
    "print(combined_one_hot.shape)\n",
    "export_csv= combined_one_hot.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\combined_one_hot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f389910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.999517\n",
      "Confusion Matrix:\n",
      "[[ 803    1]\n",
      " [   0 1266]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       1.00      1.00      1.00       804\n",
      "     Current       1.00      1.00      1.00      1266\n",
      "\n",
      "    accuracy                           1.00      2070\n",
      "   macro avg       1.00      1.00      1.00      2070\n",
      "weighted avg       1.00      1.00      1.00      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on combined data\n",
    "#clf1=RandomForestClassifier()\n",
    "RF_Comb = clf.fit(combined_one_hot,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(combined_one_hot, y_train)))\n",
    "rf_predictions = clf.predict(combined_one_hot)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdb2858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Accuracy Scores ===\n",
      "[0.85598142 0.87979094 0.86643438 0.90727836 0.875      0.9015625\n",
      " 0.84375    0.8140625  0.8796875  0.8703125  0.88869048 0.91031746\n",
      " 0.90575397 0.75257937 0.91825397 0.87281746 0.90238095 0.93869048\n",
      " 0.88194444 0.89781746]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - ON Text:  0.8781553063298488\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run cross-validation - COMBINED Data\n",
    "rf_Comb_cv_score = cross_val_score(RF_Comb, combined_one_hot, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
    "print(\"=== All Accuracy Scores ===\")\n",
    "print(rf_Comb_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean Accuracy Score ===\")\n",
    "print(\"Mean Accuracy Score - ON Text: \",rf_Comb_cv_score.mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f0560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 17)\n",
      "(2070, 9)\n",
      "   Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
      "0         1    38000.00  229.64  24.393333         3         23.56   \n",
      "1         2    29616.00   75.29  49.426667         2         29.78   \n",
      "2         0    19732.80   47.25  50.673333         3         24.81   \n",
      "3         2       96.33   59.01  56.473333         1         26.13   \n",
      "4         2    52004.80   28.14  25.140000         1          5.03   \n",
      "\n",
      "   International   Local  Dropped  \n",
      "0            0.0  206.08        0  \n",
      "1            0.0   45.50        0  \n",
      "2            0.0   22.44        0  \n",
      "3            0.0   32.88        1  \n",
      "4            0.0   23.11        0  \n",
      "(2070, 343)\n",
      "    25   26   27   28   29   30   31   32   33   34  ...  Status_S  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         1   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         1   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
      "\n",
      "   Car_Owner_N  Car_Owner_Y  Paymethod_Auto  Paymethod_CC  Paymethod_CH  \\\n",
      "0            1            0               0             1             0   \n",
      "1            1            0               0             0             1   \n",
      "2            1            0               0             1             0   \n",
      "3            1            0               0             1             0   \n",
      "4            1            0               0             0             1   \n",
      "\n",
      "   LocalBilltype_Budget  LocalBilltype_FreeLocal  \\\n",
      "0                     1                        0   \n",
      "1                     0                        1   \n",
      "2                     0                        1   \n",
      "3                     1                        0   \n",
      "4                     1                        0   \n",
      "\n",
      "   LongDistanceBilltype_Intnl_discount  LongDistanceBilltype_Standard  \n",
      "0                                    1                              0  \n",
      "1                                    0                              1  \n",
      "2                                    0                              1  \n",
      "3                                    0                              1  \n",
      "4                                    1                              0  \n",
      "\n",
      "[5 rows x 343 columns]\n",
      "(2070, 352)\n",
      "   Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
      "0         1    38000.00  229.64  24.393333         3         23.56   \n",
      "1         2    29616.00   75.29  49.426667         2         29.78   \n",
      "2         0    19732.80   47.25  50.673333         3         24.81   \n",
      "3         2       96.33   59.01  56.473333         1         26.13   \n",
      "4         2    52004.80   28.14  25.140000         1          5.03   \n",
      "\n",
      "   International   Local  Dropped   25  ...  Status_S  Car_Owner_N  \\\n",
      "0            0.0  206.08        0  0.0  ...         1            1   \n",
      "1            0.0   45.50        0  0.0  ...         0            1   \n",
      "2            0.0   22.44        0  0.0  ...         0            1   \n",
      "3            0.0   32.88        1  0.0  ...         1            1   \n",
      "4            0.0   23.11        0  0.0  ...         0            1   \n",
      "\n",
      "   Car_Owner_Y  Paymethod_Auto  Paymethod_CC  Paymethod_CH  \\\n",
      "0            0               0             1             0   \n",
      "1            0               0             0             1   \n",
      "2            0               0             1             0   \n",
      "3            0               0             1             0   \n",
      "4            0               0             0             1   \n",
      "\n",
      "   LocalBilltype_Budget  LocalBilltype_FreeLocal  \\\n",
      "0                     1                        0   \n",
      "1                     0                        1   \n",
      "2                     0                        1   \n",
      "3                     1                        0   \n",
      "4                     1                        0   \n",
      "\n",
      "   LongDistanceBilltype_Intnl_discount  LongDistanceBilltype_Standard  \n",
      "0                                    1                              0  \n",
      "1                                    0                              1  \n",
      "2                                    0                              1  \n",
      "3                                    0                              1  \n",
      "4                                    1                              0  \n",
      "\n",
      "[5 rows x 352 columns]\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier WITHOUT text data\n",
    "print(CustInfoData.shape)\n",
    "X_train1=combined_one_hot.iloc[:,1:10]\n",
    "#X_train2=combined_one_hot.iloc[:,60:]\n",
    "X_train2=combined_one_hot.iloc[:,35:]\n",
    "print(X_train1.shape)\n",
    "print(X_train1.head())\n",
    "print(X_train2.shape)\n",
    "print(X_train2.head())\n",
    "combined1=pd.concat([X_train1, X_train2], axis=1)\n",
    "print(combined1.shape)\n",
    "print(combined1.head())\n",
    "export_csv= combined1.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\combined1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec2b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.958454\n",
      "Confusion Matrix:\n",
      "[[ 762   42]\n",
      " [  44 1222]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.95      0.95      0.95       804\n",
      "     Current       0.97      0.97      0.97      1266\n",
      "\n",
      "    accuracy                           0.96      2070\n",
      "   macro avg       0.96      0.96      0.96      2070\n",
      "weighted avg       0.96      0.96      0.96      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier WITHOUT text data\n",
    "\n",
    "rf_NT=clf.fit(combined1,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(rf_NT.score(combined1, y_train)))\n",
    "rf_predictions = rf_NT.predict(combined1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffafad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== All Accuracy Scores ===\n",
      "[0.84436702 0.88404955 0.89508324 0.89934185 0.8828125  0.909375\n",
      " 0.8765625  0.821875   0.8796875  0.88125    0.90575397 0.90912698\n",
      " 0.93075397 0.8047619  0.90575397 0.88531746 0.91031746 0.91825397\n",
      " 0.88988095 0.91031746]\n",
      "\n",
      "\n",
      "=== Mean Accuracy Score ===\n",
      "Mean Accuracy Score - WITHOUT Text:  0.8872321126113046\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run cross-validation - WITHOUT Text Data\n",
    "rf_NT_cv_score = cross_val_score(rf_NT, combined1, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
    "print(\"=== All Accuracy Scores ===\")\n",
    "print(rf_NT_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean Accuracy Score ===\")\n",
    "print(\"Mean Accuracy Score - WITHOUT Text: \",rf_NT_cv_score.mean())\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd468ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customer Info One-Hot Encoded\n",
    "DF_Combined1= pd.DataFrame(combined1)\n",
    "export_csv= DF_Combined1.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\CustInfo_Onehot_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "215a0c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26633237e-01 6.75512258e-02 1.04415264e-02 8.92644242e-02\n",
      " 8.46480694e-02 1.38642421e-01 4.08505640e-03 1.17493682e-02\n",
      " 7.96102446e-03 0.00000000e+00 0.00000000e+00 1.64437255e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.92690270e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.12519783e-03 1.80423779e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.85050029e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.84748370e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.68808950e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.12271925e-05\n",
      " 0.00000000e+00 0.00000000e+00 1.61646643e-04 0.00000000e+00\n",
      " 0.00000000e+00 9.54164214e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.56350874e-03\n",
      " 0.00000000e+00 9.54164214e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 7.59934373e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.14220129e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.10773916e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.37449304e-04 3.05332548e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.55846822e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.71974241e-03 3.61609622e-03\n",
      " 0.00000000e+00 3.83646402e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.28999411e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.14499706e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.63815936e-04 0.00000000e+00 0.00000000e+00\n",
      " 3.79238559e-04 0.00000000e+00 0.00000000e+00 5.34331960e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.55555544e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.47175549e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.18512266e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.53924531e-04 0.00000000e+00 1.52334731e-01 0.00000000e+00\n",
      " 0.00000000e+00 4.92999406e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.37261764e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.85274778e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.76807509e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.72618347e-05\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.67319837e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.63331371e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.22359611e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.20644768e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.76562853e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.37965773e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.48835764e-03 7.80243215e-03\n",
      " 3.00266744e-03 7.63331371e-05 5.46371045e-02 2.51162313e-03\n",
      " 1.33061104e-03 6.30127117e-02 1.56619830e-03 2.86249264e-04\n",
      " 1.46594320e-03 2.82826464e-03 0.00000000e+00 3.75829795e-03]\n",
      "[ True  True False  True  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False False False False]\n",
      "        0         1          2    3      4         5    6\n",
      "0     1.0  38000.00  24.393333  3.0  23.56  0.000000  0.0\n",
      "1     2.0  29616.00  49.426667  2.0  29.78  0.271105  0.0\n",
      "2     0.0  19732.80  50.673333  3.0  24.81  0.271105  0.0\n",
      "3     2.0     96.33  56.473333  1.0  26.13  0.271105  0.0\n",
      "4     2.0  52004.80  25.140000  1.0   5.03  0.271105  0.0\n",
      "...   ...       ...        ...  ...    ...       ...  ...\n",
      "2065  0.0  78851.30  48.373333  4.0   0.37  0.000000  0.0\n",
      "2066  1.0  17540.70  62.786667  1.0  22.17  0.000000  1.0\n",
      "2067  0.0  83891.90  61.020000  4.0  28.92  0.000000  0.0\n",
      "2068  2.0  28220.80  38.766667  4.0  26.49  0.000000  0.0\n",
      "2069  0.0  28589.10  15.600000  3.0  13.19  0.000000  0.0\n",
      "\n",
      "[2070 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Do feature selection using a classification model\n",
    "#clf = ExtraTreesClassifier(n_estimators=50)\n",
    "#clf = GradientBoostingClassifier(n_estimators=50)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(DF_Combined1,y_train)\n",
    "print(clf.feature_importances_)\n",
    "#model = SelectFromModel(clf, prefit=True)\n",
    "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
    "#model = SelectFromModel(clf, prefit=True)\n",
    "X_new= model.transform(DF_Combined1)\n",
    "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
    "export_csv= X_new_SelectedFeatures.to_csv(r'C:\\Users\\dipti\\Documents\\CIS508\\Assignment 4\\X_new_SelectedFeatures.csv')\n",
    "\n",
    "print(model.get_support())\n",
    "print(X_new_SelectedFeatures)\n",
    "#print(X_new_SelectedFeatures.shape)\n",
    "#print(X_new_SelectedFeatures.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41f14244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clodsa==1.2.43 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (1.2.43)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (1.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (1.1.0)\n",
      "Requirement already satisfied: Keras in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (2.10.0)\n",
      "Requirement already satisfied: imutils in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (0.5.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (1.7.3)\n",
      "Requirement already satisfied: commentjson in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (0.9.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (3.7.0)\n",
      "Requirement already satisfied: progressbar2 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (4.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (1.21.5)\n",
      "Requirement already satisfied: mahotas in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from clodsa==1.2.43) (1.4.13)\n",
      "Requirement already satisfied: lark-parser<0.8.0,>=0.7.1 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from commentjson->clodsa==1.2.43) (0.7.8)\n",
      "Requirement already satisfied: python-utils>=3.0.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from progressbar2->clodsa==1.2.43) (3.4.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dipti\\anaconda3\\lib\\site-packages (from scikit-learn->clodsa==1.2.43) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 352 out of 352 | elapsed:    1.4s finished\n",
      "\n",
      "[2022-11-16 11:49:35] Features: 1/9 -- score: 0.8985507246376812[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 351 out of 351 | elapsed:    1.9s finished\n",
      "\n",
      "[2022-11-16 11:49:37] Features: 2/9 -- score: 0.9338164251207729[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 350 out of 350 | elapsed:    2.2s finished\n",
      "\n",
      "[2022-11-16 11:49:39] Features: 3/9 -- score: 0.9502415458937198[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 349 out of 349 | elapsed:    2.0s finished\n",
      "\n",
      "[2022-11-16 11:49:41] Features: 4/9 -- score: 0.9541062801932367[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 348 out of 348 | elapsed:    2.1s finished\n",
      "\n",
      "[2022-11-16 11:49:43] Features: 5/9 -- score: 0.9565217391304348[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 347 out of 347 | elapsed:    2.1s finished\n",
      "\n",
      "[2022-11-16 11:49:46] Features: 6/9 -- score: 0.957487922705314[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 346 out of 346 | elapsed:    2.3s finished\n",
      "\n",
      "[2022-11-16 11:49:48] Features: 7/9 -- score: 0.9579710144927536[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 345 out of 345 | elapsed:    2.3s finished\n",
      "\n",
      "[2022-11-16 11:49:51] Features: 8/9 -- score: 0.9584541062801932[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 344 out of 344 | elapsed:    2.4s finished\n",
      "\n",
      "[2022-11-16 11:49:53] Features: 9/9 -- score: 0.9584541062801932"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (2,),\n",
       "  'cv_scores': array([0.89855072]),\n",
       "  'avg_score': 0.8985507246376812,\n",
       "  'feature_names': ('Usage',)},\n",
       " 2: {'feature_idx': (2, 4),\n",
       "  'cv_scores': array([0.93381643]),\n",
       "  'avg_score': 0.9338164251207729,\n",
       "  'feature_names': ('Usage', 'RatePlan')},\n",
       " 3: {'feature_idx': (2, 3, 4),\n",
       "  'cv_scores': array([0.95024155]),\n",
       "  'avg_score': 0.9502415458937198,\n",
       "  'feature_names': ('Usage', 'Age', 'RatePlan')},\n",
       " 4: {'feature_idx': (2, 3, 4, 5),\n",
       "  'cv_scores': array([0.95410628]),\n",
       "  'avg_score': 0.9541062801932367,\n",
       "  'feature_names': ('Usage', 'Age', 'RatePlan', 'LongDistance')},\n",
       " 5: {'feature_idx': (0, 2, 3, 4, 5),\n",
       "  'cv_scores': array([0.95652174]),\n",
       "  'avg_score': 0.9565217391304348,\n",
       "  'feature_names': ('Children', 'Usage', 'Age', 'RatePlan', 'LongDistance')},\n",
       " 6: {'feature_idx': (0, 2, 3, 4, 5, 319),\n",
       "  'cv_scores': array([0.95748792]),\n",
       "  'avg_score': 0.957487922705314,\n",
       "  'feature_names': ('Children',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   335)},\n",
       " 7: {'feature_idx': (0, 1, 2, 3, 4, 5, 319),\n",
       "  'cv_scores': array([0.95797101]),\n",
       "  'avg_score': 0.9579710144927536,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   335)},\n",
       " 8: {'feature_idx': (0, 1, 2, 3, 4, 5, 319, 346),\n",
       "  'cv_scores': array([0.95845411]),\n",
       "  'avg_score': 0.9584541062801932,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   335,\n",
       "   'Paymethod_CC')},\n",
       " 9: {'feature_idx': (0, 1, 2, 3, 4, 5, 6, 319, 346),\n",
       "  'cv_scores': array([0.95845411]),\n",
       "  'avg_score': 0.9584541062801932,\n",
       "  'feature_names': ('Children',\n",
       "   'Est_Income',\n",
       "   'Usage',\n",
       "   'Age',\n",
       "   'RatePlan',\n",
       "   'LongDistance',\n",
       "   'International',\n",
       "   335,\n",
       "   'Paymethod_CC')}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequential Forward Search\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "!pip install clodsa==1.2.43\n",
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "sfs1 = SFS(clf, \n",
    "           k_features=9, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(DF_Combined1,y_train)\n",
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3c6462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Children', 'Est_Income', 'Usage', 'Age', 'RatePlan', 'LongDistance', 'International', 335, 'Paymethod_CC')\n",
      "0.9584541062801932\n"
     ]
    }
   ],
   "source": [
    "#Sequential forward search result\n",
    "print(sfs1.k_feature_names_)\n",
    "print(sfs1.k_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a3137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
